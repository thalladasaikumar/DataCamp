{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reshaping your data using melt</h1>\n",
    "<div class=\"\"><p>Melting data is the process of turning columns of your data into rows of data. Consider the DataFrames from the previous exercise. In the tidy DataFrame, the variables <code>Ozone</code>, <code>Solar.R</code>, <code>Wind</code>, and <code>Temp</code> each had their own column.\n",
    "If, however, you wanted these variables to be in rows instead, you could melt the DataFrame. In doing so, however, you would make the data untidy! This is important to keep in mind: Depending on how your data is represented, you will have to reshape it\n",
    "differently (e.g., this could make it easier to plot values).</p>\n",
    "<p>In this exercise, you will practice melting a DataFrame using <code>pd.melt()</code>. There are two parameters you should be aware of: <code>id_vars</code> and <code>value_vars</code>.\n",
    "The <code>id_vars</code> represent the columns of the data you <strong>do not</strong> want to melt (i.e., keep it in its current shape), while the <code>value_vars</code> represent the columns you <strong>do</strong> wish to melt into rows.  By default, if no <code>value_vars</code> are provided, all columns not set in the <code>id_vars</code> will be melted. This could save a bit of typing, depending on the number of columns that need to be melted.</p>\n",
    "<p>The (tidy) DataFrame <code>airquality</code> has been pre-loaded. Your job is to melt its <code>Ozone</code>, <code>Solar.R</code>, <code>Wind</code>, and <code>Temp</code> columns into rows. Later in this chapter, you'll learn how to bring this melted DataFrame back into a tidy form.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Ozone  Solar.R  Wind  Temp\n",
      "0  1973-05-01   41.0    190.0   7.4    67\n",
      "1  1973-05-02   36.0    118.0   8.0    72\n",
      "2  1973-05-03   12.0    149.0  12.6    74\n",
      "3  1973-05-04   18.0    313.0  11.5    62\n",
      "4  1973-05-05    NaN      NaN  14.3    56\n",
      "         Date variable  value\n",
      "0  1973-05-01    Ozone   41.0\n",
      "1  1973-05-02    Ozone   36.0\n",
      "2  1973-05-03    Ozone   12.0\n",
      "3  1973-05-04    Ozone   18.0\n",
      "4  1973-05-05    Ozone    NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airquality = pd.read_csv('airquality.csv')\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(frame=airquality, id_vars='Date',\n",
    "    value_vars=['Ozone', 'Solar.R', 'Wind', 'Temp'])\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise--assignment exercise--typography\"><h1 class=\"exercise--title\">Customizing melted data</h1><div class=\"\"><p>When melting DataFrames, it would be better to have column names more meaningful than <code>variable</code> and <code>value</code> (the default names used by <code>pd.melt()</code>).</p>\n",
    "<p>The default names may work in certain situations, but it's best to always have data that is self explanatory.</p>\n",
    "<p>You can rename the <code>variable</code> column by specifying an argument to the <code>var_name</code> parameter, and the <code>value</code>\n",
    "column by specifying an argument to the <code>value_name</code> parameter. You will now practice doing exactly this.\n",
    "Pandas as <code>pd</code> and the DataFrame <code>airquality</code> has been pre-loaded for you.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Ozone  Solar.R  Wind  Temp\n",
      "0  1973-05-01   41.0    190.0   7.4    67\n",
      "1  1973-05-02   36.0    118.0   8.0    72\n",
      "2  1973-05-03   12.0    149.0  12.6    74\n",
      "3  1973-05-04   18.0    313.0  11.5    62\n",
      "4  1973-05-05    NaN      NaN  14.3    56\n",
      "         Date measurement  reading\n",
      "0  1973-05-01       Ozone     41.0\n",
      "1  1973-05-02       Ozone     36.0\n",
      "2  1973-05-03       Ozone     12.0\n",
      "3  1973-05-04       Ozone     18.0\n",
      "4  1973-05-05       Ozone      NaN\n"
     ]
    }
   ],
   "source": [
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "# Melt airquality: airquality_melt\n",
    "airquality_melt = pd.melt(airquality, id_vars='Date', var_name='measurement', value_name='reading')\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise--assignment exercise--typography\"><h1 class=\"exercise--title\">Pivot data</h1><div class=\"\"><p>Pivoting data is the opposite of melting it. Remember the tidy form that the <code>airquality</code> DataFrame was in before you melted it? You'll now begin pivoting it back into that form using the <code>.pivot_table()</code> method!</p>\n",
    "<p>While melting takes a set of columns and turns it into a single column, pivoting will create a new column for each unique value in a specified column.</p>\n",
    "<p><code>.pivot_table()</code> has an <code>index</code> parameter which you can use to specify the columns that you <em>don't</em> want pivoted: It is similar to the <code>id_vars</code> parameter of <code>pd.melt()</code>. Two other parameters that you have to specify are <code>columns</code> (the name of the column you want to pivot), and <code>values</code> (the values to be used when the column is pivoted). The melted DataFrame <code>airquality_melt</code> has been pre-loaded for you.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n",
      "   Month  Day measurement  reading\n",
      "0      5    1       Ozone     41.0\n",
      "1      5    2       Ozone     36.0\n",
      "2      5    3       Ozone     12.0\n",
      "3      5    4       Ozone     18.0\n",
      "4      5    5       Ozone      NaN\n",
      "measurement  Ozone  Solar.R  Temp  Wind\n",
      "Month Day                              \n",
      "5     1       41.0    190.0  67.0   7.4\n",
      "      2       36.0    118.0  72.0   8.0\n",
      "      3       12.0    149.0  74.0  12.6\n",
      "      4       18.0    313.0  62.0  11.5\n",
      "      5        NaN      NaN  56.0  14.3\n"
     ]
    }
   ],
   "source": [
    "import requests, os\n",
    "res = requests.get('https://raw.githubusercontent.com/wblakecannon/DataCamp/master/10-cleaning-data-in-python/_datasets/airquality.csv')\n",
    "csvFile = open('airquality2.csv','wb')\n",
    "for chunk in res.iter_content(100000):\n",
    "    csvFile.write(chunk)\n",
    "csvFile.close()\n",
    "\n",
    "airquality = pd.read_csv('airquality2.csv')\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())\n",
    "\n",
    "airquality_melt = pd.melt(frame=airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')\n",
    "\n",
    "# Print the head of airquality_melt\n",
    "print(airquality_melt.head())\n",
    "\n",
    "# Pivot airquality_melt: airquality_pivot\n",
    "airquality_pivot = airquality_melt.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading')\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise--assignment exercise--typography\"><h1 class=\"exercise--title\">Resetting the index of a DataFrame</h1><div class=\"\"><p>After pivoting <code>airquality_melt</code> in the previous exercise, you didn't quite get back the original DataFrame.</p>\n",
    "<p>What you got back instead was a pandas DataFrame with a <a href=\"http://pandas.pydata.org/pandas-docs/stable/advanced.html\" target=\"_blank\" rel=\"noopener noreferrer\">hierarchical index (also known as a MultiIndex)</a>.</p>\n",
    "<p>Hierarchical indexes are covered in depth in <a href=\"https://www.datacamp.com/courses/manipulating-dataframes-with-pandas\" target=\"_blank\" rel=\"noopener noreferrer\">Manipulating DataFrames with pandas</a>.\n",
    "In essence, they allow you to group columns or rows by another variable - in this case, by <code>'Month'</code> as well as <code>'Day'</code>. </p>\n",
    "<p>There's a very simple method you can use to get back the original DataFrame from the pivoted DataFrame: <code>.reset_index()</code>. Dan didn't show you how to use this method in the video, but you're now going to practice using it in this exercise to get back the original DataFrame from <code>airquality_pivot</code>, which has been pre-loaded.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(5,  1),\n",
      "            (5,  2),\n",
      "            (5,  3),\n",
      "            (5,  4),\n",
      "            (5,  5),\n",
      "            (5,  6),\n",
      "            (5,  7),\n",
      "            (5,  8),\n",
      "            (5,  9),\n",
      "            (5, 10),\n",
      "            ...\n",
      "            (9, 21),\n",
      "            (9, 22),\n",
      "            (9, 23),\n",
      "            (9, 24),\n",
      "            (9, 25),\n",
      "            (9, 26),\n",
      "            (9, 27),\n",
      "            (9, 28),\n",
      "            (9, 29),\n",
      "            (9, 30)],\n",
      "           names=['Month', 'Day'], length=153)\n",
      "RangeIndex(start=0, stop=153, step=1)\n",
      "measurement  Month  Day  Ozone  Solar.R  Temp  Wind\n",
      "0                5    1   41.0    190.0  67.0   7.4\n",
      "1                5    2   36.0    118.0  72.0   8.0\n",
      "2                5    3   12.0    149.0  74.0  12.6\n",
      "3                5    4   18.0    313.0  62.0  11.5\n",
      "4                5    5    NaN      NaN  56.0  14.3\n"
     ]
    }
   ],
   "source": [
    "# Print the index of airquality_pivot\n",
    "print(airquality_pivot.index)\n",
    "\n",
    "# Reset the index of airquality_pivot: airquality_pivot_reset\n",
    "airquality_pivot_reset = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the new index of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.index)\n",
    "\n",
    "# Print the head of airquality_pivot_reset\n",
    "print(airquality_pivot_reset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise--assignment exercise--typography\"><h1 class=\"exercise--title\">Pivoting duplicate values</h1><div class=\"\"><p>So far, you've used the <code>.pivot_table()</code> method when there are multiple <code>index</code> values you want to hold constant during a pivot. In the video, Dan showed you how you can also use pivot tables to deal with duplicate values by providing an aggregation function through the <code>aggfunc</code> parameter. Here, you're going to combine both these uses of pivot tables.</p>\n",
    "<p>Let's say your data collection method accidentally duplicated your dataset. Such a dataset, in which each row is duplicated, has been pre-loaded as <code>airquality_dup</code>. In addition, the <code>airquality_melt</code> DataFrame from the previous exercise has been pre-loaded. Explore their shapes in the IPython Shell by accessing their <code>.shape</code> attributes to confirm the duplicate rows present in <code>airquality_dup</code>.</p>\n",
    "<p>You'll see that by using <code>.pivot_table()</code> and the <code>aggfunc</code> parameter, you can not only reshape your data, but also remove duplicates. Finally, you can then flatten the columns of the pivoted DataFrame using <code>.reset_index()</code>.</p>\n",
    "<p>NumPy and pandas have been imported as <code>np</code> and <code>pd</code> respectively.</p></div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measurement  Ozone  Solar.R  Temp  Wind\n",
      "Date                                   \n",
      "1973-05-01    41.0    190.0  67.0   7.4\n",
      "1973-05-02    36.0    118.0  72.0   8.0\n",
      "1973-05-03    12.0    149.0  74.0  12.6\n",
      "1973-05-04    18.0    313.0  62.0  11.5\n",
      "1973-05-05     NaN      NaN  56.0  14.3\n",
      "measurement        Date  Ozone  Solar.R  Temp  Wind\n",
      "0            1973-05-01   41.0    190.0  67.0   7.4\n",
      "1            1973-05-02   36.0    118.0  72.0   8.0\n",
      "2            1973-05-03   12.0    149.0  74.0  12.6\n",
      "3            1973-05-04   18.0    313.0  62.0  11.5\n",
      "4            1973-05-05    NaN      NaN  56.0  14.3\n",
      "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
      "0   41.0    190.0   7.4    67      5    1\n",
      "1   36.0    118.0   8.0    72      5    2\n",
      "2   12.0    149.0  12.6    74      5    3\n",
      "3   18.0    313.0  11.5    62      5    4\n",
      "4    NaN      NaN  14.3    56      5    5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "airquality_dup = pd.read_csv('airquality_dup.csv')\n",
    "\n",
    "# Pivot table the airquality_dup: airquality_pivot\n",
    "airquality_pivot = airquality_dup.pivot_table(index='Date', columns='measurement', values='reading', aggfunc=np.mean)\n",
    "\n",
    "# Print the head of airquality_pivot before reset_index\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Reset the index of airquality_pivot\n",
    "airquality_pivot = airquality_pivot.reset_index()\n",
    "\n",
    "# Print the head of airquality_pivot\n",
    "print(airquality_pivot.head())\n",
    "\n",
    "# Print the head of airquality\n",
    "print(airquality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting a column with .str</h1>\n",
    "<div class=\"\"><p>The dataset you saw in the video, consisting of case counts of tuberculosis by country, year, gender, and age group, has been pre-loaded into a DataFrame as <code>tb</code>.</p>\n",
    "<p>In this exercise, you're going to tidy the <code>'m014'</code> column, which represents males aged 0-14 years of age.\n",
    "In order to parse this value, you need to extract the first letter into a new column for <code>gender</code>, and the rest into a column for <code>age_group</code>.\n",
    "Here, since you can parse values by position, you can take advantage of pandas' vectorized string slicing by using the <code>str</code> attribute of columns of type <code>object</code>.</p>\n",
    "<p>Begin by printing the columns of <code>tb</code> in the IPython Shell using its <code>.columns</code> attribute, and take note of the problematic column.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  year  m014  m1524  m2534  m3544  m4554  m5564   m65  mu  f014  \\\n",
      "0      AD  2000   0.0    0.0    1.0    0.0    0.0    0.0   0.0 NaN   NaN   \n",
      "1      AE  2000   2.0    4.0    4.0    6.0    5.0   12.0  10.0 NaN   3.0   \n",
      "2      AF  2000  52.0  228.0  183.0  149.0  129.0   94.0  80.0 NaN  93.0   \n",
      "3      AG  2000   0.0    0.0    0.0    0.0    0.0    0.0   1.0 NaN   1.0   \n",
      "4      AL  2000   2.0   19.0   21.0   14.0   24.0   19.0  16.0 NaN   3.0   \n",
      "\n",
      "   f1524  f2534  f3544  f4554  f5564   f65  fu  \n",
      "0    NaN    NaN    NaN    NaN    NaN   NaN NaN  \n",
      "1   16.0    1.0    3.0    0.0    0.0   4.0 NaN  \n",
      "2  414.0  565.0  339.0  205.0   99.0  36.0 NaN  \n",
      "3    1.0    1.0    0.0    0.0    0.0   0.0 NaN  \n",
      "4   11.0   10.0    8.0    8.0    5.0  11.0 NaN  \n",
      "  country  year variable  value gender age_group\n",
      "0      AD  2000     m014    0.0      m       014\n",
      "1      AE  2000     m014    2.0      m       014\n",
      "2      AF  2000     m014   52.0      m       014\n",
      "3      AG  2000     m014    0.0      m       014\n",
      "4      AL  2000     m014    2.0      m       014\n"
     ]
    }
   ],
   "source": [
    "tb = pd.read_csv('tb.csv', index_col=0)\n",
    "print(tb.head())\n",
    "# Melt tb: tb_melt\n",
    "tb_melt = pd.melt(frame=tb, id_vars=['country', 'year'])\n",
    "\n",
    "# Create the 'gender' column\n",
    "tb_melt['gender'] = tb_melt.variable.str[0]\n",
    "\n",
    "# Create the 'age_group' column\n",
    "tb_melt['age_group'] = tb_melt.variable.str[1:]\n",
    "\n",
    "# Print the head of tb_melt\n",
    "print(tb_melt.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting a column with .split() and .get()</h1>\n",
    "<div class=\"\"><p>Another common way <strong>multiple variables are stored in columns</strong> is with a delimiter. You'll learn how to deal with such cases in this exercise,\n",
    "using a <a href=\"https://data.humdata.org/dataset/ebola-cases-2014\" target=\"_blank\" rel=\"noopener noreferrer\">dataset consisting of Ebola cases and death counts by state and country</a>. It has been pre-loaded into a DataFrame as <code>ebola</code>.</p>\n",
    "<p>Print the columns of <code>ebola</code> in the IPython Shell using <code>ebola.columns</code>. Notice that the data has column names such as <code>Cases_Guinea</code> and <code>Deaths_Guinea</code>. Here,\n",
    "the underscore <code>_</code> serves as a delimiter between the first part (cases or deaths), and the second part (country).</p>\n",
    "<p>This time, you cannot directly slice the variable by position as in the previous exercise. You now need to use Python's built-in string method called <code>.split()</code>. By default,\n",
    "this method will split a string into parts separated by a space. However, in this case you want it to split by an underscore. You can do this on <code>'Cases_Guinea'</code>, for example,\n",
    "using <code>'Cases_Guinea'.split('_')</code>, which returns the list <code>['Cases', 'Guinea']</code>.</p>\n",
    "<p>The next challenge is to extract the first element of this list and assign it to a <code>type</code> variable, and the second element of the list to a <code>country</code> variable. You can accomplish this by accessing the <code>str</code> attribute of the column and using the <code>.get()</code> method to retrieve the <code>0</code> or <code>1</code> index, depending on the part you want.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  type_country  counts        str_split   type country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  [Cases, Guinea]  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  [Cases, Guinea]  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  [Cases, Guinea]  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  [Cases, Guinea]  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  [Cases, Guinea]  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "ebola = pd.read_csv('ebola.csv')\n",
    "\n",
    "# Melt ebola: ebola_melt\n",
    "ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country', value_name='counts')\n",
    "\n",
    "# Create the 'str_split' column\n",
    "ebola_melt['str_split'] = ebola_melt['type_country'].str.split('_')\n",
    "\n",
    "# Create the 'type' column\n",
    "ebola_melt['type'] = ebola_melt['str_split'].str.get(0)\n",
    "\n",
    "# Create the 'country' column\n",
    "ebola_melt['country'] = ebola_melt['str_split'].str.get(1)\n",
    "\n",
    "# Print the head of ebola_melt\n",
    "print(ebola_melt.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
